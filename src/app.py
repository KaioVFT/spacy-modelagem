import streamlit as st
import joblib
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import spacy

from preprocess import processar_texto, NLP

# --- CONFIGURA√á√ïES DE CAMINHO ---
BASE_DIR = Path(__file__).resolve().parent.parent
MODEL_PATH = BASE_DIR / "models" / "logistic_regression_model.joblib"
VECTORIZER_PATH = BASE_DIR / "models" / "tfidf_vectorizer.joblib"

@st.cache_resource
def carregar_classificador() -> tuple:
    """Carrega o modelo de classifica√ß√£o de not√≠cias e o vetorizador."""
    if not MODEL_PATH.exists() or not VECTORIZER_PATH.exists():
        return None, None
    modelo = joblib.load(MODEL_PATH)
    vetorizador = joblib.load(VECTORIZER_PATH)
    return modelo, vetorizador

@st.cache_resource
def carregar_pipeline_sentimento():
    """Carrega o pipeline de an√°lise de sentimentos da Hugging Face."""
    from transformers import pipeline
    # Usando modelo p√∫blico e est√°vel
    return pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

modelo_classificador, vetorizador = carregar_classificador()
pipeline_sentimento = carregar_pipeline_sentimento()

st.set_page_config(page_title="An√°lise de Not√≠cias", page_icon="üî¨", layout="centered")
st.title("üî¨ Ferramenta de An√°lise de Not√≠cias")
st.markdown("Navegue pelas abas abaixo para usar as diferentes funcionalidades de Processamento de Linguagem Natural.")

tab1, tab2 = st.tabs(["Detector de Fake News", "An√°lises Avan√ßadas (POS e Sentimento)"])

# --- ABA 1: DETECTOR DE FAKE NEWS ---
with tab1:
    st.header("Classifica√ß√£o de Not√≠cias (Verdadeira ou Falsa)")
    st.markdown("Cole o t√≠tulo de uma not√≠cia para descobrir se ela √© provavelmente verdadeira ou falsa.")

    if modelo_classificador is None or vetorizador is None:
        st.error("‚ö†Ô∏è Modelo de classifica√ß√£o n√£o encontrado! Treine o modelo primeiro (`python src/train.py`).")
    else:
        texto_noticia_classificar = st.text_area("Texto da not√≠cia para classificar", height=150, key="text_classifier")
        if st.button("Classificar", type="primary", use_container_width=True, key="btn_classifier"):
            if texto_noticia_classificar.strip():
                texto_processado = processar_texto(texto_noticia_classificar)
                vetor_texto = vetorizador.transform([texto_processado])
                predicao = modelo_classificador.predict(vetor_texto)
                probabilidade = modelo_classificador.predict_proba(vetor_texto)
                conf_falsa, conf_verdadeira = probabilidade[0]

                st.markdown("---")
                st.subheader("Resultado da Classifica√ß√£o")
                if predicao[0] == 1:
                    st.success("‚úÖ Resultado: VERDADEIRA")
                    st.progress(conf_verdadeira, text=f"Confian√ßa: {conf_verdadeira:.1%}")
                else:
                    st.error("‚ùå Resultado: FALSA")
                    st.progress(conf_falsa, text=f"Confian√ßa: {conf_falsa:.1%}")
            else:
                st.warning("Por favor, insira um texto para classificar.")

# --- ABA 2: AN√ÅLISES AVAN√áADAS ---
with tab2:
    st.header("An√°lise de Texto (POS Tagging e Sentimento)")
    st.markdown("Cole um texto qualquer para extrair suas classes gramaticais (POS Tagging) e analisar seu sentimento.")

    texto_analise_avancada = st.text_area("Texto para an√°lise avan√ßada", height=150, key="text_advanced")
    if st.button("Analisar Texto", type="primary", use_container_width=True, key="btn_advanced"):
        if texto_analise_avancada.strip():
            doc = NLP(texto_analise_avancada)
            st.markdown("---")
            st.subheader("üìä An√°lise de Classes Gramaticais (Part-of-Speech Tagging)")

            pos_data = [(token.text, token.lemma_, token.pos_, spacy.explain(token.pos_)) for token in doc if not token.is_punct]
            df_pos = pd.DataFrame(pos_data, columns=["Token", "Lema", "POS Tag", "Descri√ß√£o"])
            st.dataframe(df_pos)

            st.markdown("#### Frequ√™ncia das Classes Gramaticais")
            fig, ax = plt.subplots(figsize=(8, 4))  # Tamanho reduzido
            pos_counts = df_pos['POS Tag'].value_counts()
            sns.barplot(x=pos_counts.index, y=pos_counts.values, ax=ax, palette="viridis")
            ax.set_title("Contagem de Classes Gramaticais (POS)")
            ax.set_ylabel("Frequ√™ncia")
            plt.xticks(rotation=45)
            st.pyplot(fig)

            st.markdown("---")
            st.subheader("üòä An√°lise de Sentimento")
            resultado_sentimento = pipeline_sentimento(texto_analise_avancada)
            # O modelo retorna labels como '1 star', '2 stars', ..., '5 stars'
            label_map = {
                '1 star': 'Muito Negativo',
                '2 stars': 'Negativo',
                '3 stars': 'Neutro',
                '4 stars': 'Positivo',
                '5 stars': 'Muito Positivo'
            }
            sentimento = label_map.get(resultado_sentimento[0]['label'], resultado_sentimento[0]['label'])
            score = resultado_sentimento[0]['score']

            if 'Positivo' in sentimento:
                st.success(f"Sentimento: {sentimento} (Confian√ßa: {score:.1%})")
            elif 'Negativo' in sentimento:
                st.error(f"Sentimento: {sentimento} (Confian√ßa: {score:.1%})")
            else:
                st.info(f"Sentimento: {sentimento} (Confian√ßa: {score:.1%})")

            fig_sent, ax_sent = plt.subplots(figsize=(8, 4))  # Tamanho reduzido
            sns.barplot(x=[sentimento], y=[score], ax=ax_sent, palette="rocket")
            ax_sent.set_title("Resultado da An√°lise de Sentimento")
            ax_sent.set_ylabel("Confian√ßa")
            ax_sent.set_ylim(0, 1)
            st.pyplot(fig_sent)
        else:
            st.warning("Por favor, insira um texto para analisar.")